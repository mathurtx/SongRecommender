{"paragraphs":[{"text":"import sqlContext.implicits._\nval usageData = sc.textFile(\"/Users/mathurtx/Documents/machine_learning/data/lastfm-dataset-1K/userid-timestamp-artid-artname-traid-traname.tsv\").map(line => line.split(\"\\t\"))\n\ncase class Record(val1: String, val2: String, val3: String, val4: String, val5: String, val6: String)\nval df = usageData.map({ \n  case Array(val1: String, val2: String, val3: String, val4: String, val5: String, val6: String) => Record(val1, val2,val3, val4,val5,val6)\n}).toDF(\"userId\", \"timestamp\",\"artist_id\",\"artist_name\",\"track_id\",\"track_name\")","dateUpdated":"2016-12-14T07:40:44-0500","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1481588567235_1360241762","id":"20161212-192247_1991670082","result":{"code":"SUCCESS","type":"TEXT","msg":"\nimport sqlContext.implicits._\n\nusageData: org.apache.spark.rdd.RDD[Array[String]] = MapPartitionsRDD[2] at map at <console>:32\n\ndefined class Record\n\ndf: org.apache.spark.sql.DataFrame = [userId: string, timestamp: string ... 4 more fields]\n"},"dateCreated":"2016-12-12T07:22:47-0500","dateStarted":"2016-12-14T07:40:44-0500","dateFinished":"2016-12-14T07:41:04-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2585"},{"text":"val usageDataCount = df.groupBy($\"userId\",$\"track_name\").count()","dateUpdated":"2016-12-14T07:41:35-0500","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1481660432419_-907727784","id":"20161213-152032_1314734721","result":{"code":"SUCCESS","type":"TEXT","msg":"\nusageDataCount: org.apache.spark.sql.DataFrame = [userId: string, track_name: string ... 1 more field]\n"},"dateCreated":"2016-12-13T03:20:32-0500","dateStarted":"2016-12-14T07:41:35-0500","dateFinished":"2016-12-14T07:41:35-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2586"},{"text":"import org.apache.spark.ml.feature.{StringIndexer,IndexToString}\nval trackIdIndexer = new StringIndexer()\n    .setInputCol(\"track_name\")\n    .setOutputCol(\"track_name_index\")\nval trackIndexed = trackIdIndexer.fit(usageDataCount).transform(usageDataCount)\ntrackIndexed.printSchema","dateUpdated":"2016-12-14T07:41:39-0500","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1481760466822_1115466510","id":"20161214-190746_1332189474","result":{"code":"SUCCESS","type":"TEXT","msg":"\nimport org.apache.spark.ml.feature.{StringIndexer, IndexToString}\n\ntrackIdIndexer: org.apache.spark.ml.feature.StringIndexer = strIdx_157c005778d4\n\ntrackIndexed: org.apache.spark.sql.DataFrame = [userId: string, track_name: string ... 2 more fields]\nroot\n |-- userId: string (nullable = true)\n |-- track_name: string (nullable = true)\n |-- count: long (nullable = false)\n |-- track_name_index: double (nullable = true)\n\n"},"dateCreated":"2016-12-14T07:07:46-0500","dateStarted":"2016-12-14T07:41:39-0500","dateFinished":"2016-12-14T07:42:50-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2587"},{"text":"val trackIndexName = trackIndexed.select($\"track_name_index\", $\"track_name\")\nval trackIndexNamed = trackIndexName.withColumn(\"track_name_index\", trackIndexName(\"track_name_index\").cast(\"int\"))\ntrackIndexNamed\n.coalesce(1)\n.write.format(\"com.databricks.spark.csv\")\n.option(\"header\", \"false\")\n.save(\"/Users/mathurtx/Documents/machine_learning/data/lastfm-dataset-1K/trackIndexNamev5.csv\")","dateUpdated":"2016-12-14T07:43:27-0500","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1481760529504_1794441049","id":"20161214-190849_1393418370","result":{"code":"SUCCESS","type":"TEXT","msg":"\ntrackIndexName: org.apache.spark.sql.DataFrame = [track_name_index: double, track_name: string]\n\ntrackIndexNamed: org.apache.spark.sql.DataFrame = [track_name_index: int, track_name: string]\n"},"dateCreated":"2016-12-14T07:08:49-0500","dateStarted":"2016-12-14T07:43:27-0500","dateFinished":"2016-12-14T07:44:08-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2588"},{"text":"import org.apache.spark.ml.feature.{StringIndexer,IndexToString}\nval userIndexer = new StringIndexer()\n  .setInputCol(\"userId\")\n  .setOutputCol(\"user_index\")\nval userIndexed = userIndexer.fit(trackIndexed).transform(trackIndexed)\nuserIndexed.printSchema","dateUpdated":"2016-12-14T07:44:21-0500","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1481660514365_824350467","id":"20161213-152154_555922762","result":{"code":"SUCCESS","type":"TEXT","msg":"\nimport org.apache.spark.ml.feature.{StringIndexer, IndexToString}\n\nuserIndexer: org.apache.spark.ml.feature.StringIndexer = strIdx_379c58017064\n\nuserIndexed: org.apache.spark.sql.DataFrame = [userId: string, track_name: string ... 3 more fields]\nroot\n |-- userId: string (nullable = true)\n |-- track_name: string (nullable = true)\n |-- count: long (nullable = false)\n |-- track_name_index: double (nullable = true)\n |-- user_index: double (nullable = true)\n\n"},"dateCreated":"2016-12-13T03:21:54-0500","dateStarted":"2016-12-14T07:44:21-0500","dateFinished":"2016-12-14T07:45:12-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2589"},{"text":"val userIndexName = userIndexed.select($\"user_index\", $\"userId\").distinct()\nval userIndexNamed = userIndexName.withColumn(\"user_index\", userIndexName(\"user_index\").cast(\"int\"))\nuserIndexNamed.\ncoalesce(1)\n.write.format(\"com.databricks.spark.csv\")\n.option(\"header\", \"false\")\n.save(\"/Users/mathurtx/Documents/machine_learning/data/lastfm-dataset-1K/userIndexNamev5.csv\")","dateUpdated":"2016-12-14T07:45:35-0500","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1481759718433_1430303313","id":"20161214-185518_358944235","result":{"code":"SUCCESS","type":"TEXT","msg":"\nuserIndexName: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [user_index: double, userId: string]\n\nuserIndexNamed: org.apache.spark.sql.DataFrame = [user_index: int, userId: string]\n"},"dateCreated":"2016-12-14T06:55:18-0500","dateStarted":"2016-12-14T07:45:35-0500","dateFinished":"2016-12-14T07:46:28-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2590"},{"text":"val colabData = userIndexed.select($\"user_index\",$\"track_name_index\",$\"count\")","dateUpdated":"2016-12-14T07:46:43-0500","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1481660720705_-157838498","id":"20161213-152520_401180390","result":{"code":"SUCCESS","type":"TEXT","msg":"\ncolabData: org.apache.spark.sql.DataFrame = [user_index: double, track_name_index: double ... 1 more field]\n"},"dateCreated":"2016-12-13T03:25:20-0500","dateStarted":"2016-12-14T07:46:43-0500","dateFinished":"2016-12-14T07:46:44-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2591"},{"text":"import org.apache.spark.sql.functions._\nval colabDataCasted = colabData.withColumn(\"User_Index\", colabData(\"user_index\").cast(\"int\"))\n                               .withColumn(\"Track_Name_index\", colabData(\"track_name_index\").cast(\"int\"))\n                               .withColumn(\"Count\", colabData(\"count\").cast(\"double\"))","dateUpdated":"2016-12-14T07:46:47-0500","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1481661334352_-358215531","id":"20161213-153534_1976412251","result":{"code":"SUCCESS","type":"TEXT","msg":"\nimport org.apache.spark.sql.functions._\n\ncolabDataCasted: org.apache.spark.sql.DataFrame = [User_Index: int, Track_Name_index: int ... 1 more field]\n"},"dateCreated":"2016-12-13T03:35:34-0500","dateStarted":"2016-12-14T07:46:47-0500","dateFinished":"2016-12-14T07:46:47-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2592"},{"text":"colabDataCasted.\ncoalesce(1)\n.write.format(\"com.databricks.spark.csv\")\n.option(\"header\", \"false\")\n.save(\"/Users/mathurtx/Documents/machine_learning/data/lastfm-dataset-1K/usageColabDataCastedv5.csv\")","dateUpdated":"2016-12-14T07:46:52-0500","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1481660720505_128414683","id":"20161213-152520_380050606","result":{"code":"SUCCESS","type":"TEXT","msg":""},"dateCreated":"2016-12-13T03:25:20-0500","dateStarted":"2016-12-14T07:46:52-0500","dateFinished":"2016-12-14T07:47:39-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2593"},{"text":"import org.apache.spark.ml.evaluation.RegressionEvaluator\nimport org.apache.spark.ml.recommendation.ALS\n\ncase class Rating(userId: Int, movieId: Int, rating: Float, timestamp: Long)\ndef parseRating(str: String): Rating = {\n  val fields = str.split(\",\")\n  assert(fields.size == 4)\n  Rating(fields(0).toInt, fields(1).toInt, fields(2).toFloat, fields(3).toLong)\n}\n","dateUpdated":"2016-12-14T07:07:48-0500","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1481717238566_-368412154","id":"20161214-070718_1214076887","dateCreated":"2016-12-14T07:07:18-0500","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:2594"},{"text":"import org.apache.spark.{SparkConf, SparkContext}\nimport org.apache.spark.mllib.recommendation.{ALS, Rating, MatrixFactorizationModel}\nimport org.apache.log4j.Logger\nimport org.apache.log4j.Level\nimport org.apache.spark.rdd._\n\n\n  \n    val ratings = sc.textFile(\"/Users/mathurtx/Documents/machine_learning/data/lastfm-dataset-1K/usageColabDataCastedv5.csv\").map { line =>\n    val fields = line.split(\",\")\n      ( Rating(fields(0).toInt, fields(1).toInt, fields(2).toDouble))\n    }\n\n    val numRatings = ratings.count()\n    val numUsers =  ratings.map(_.user).distinct().count()\n    val numSongs = ratings.map(_.product).distinct().count()\n\n    println(\"Got \" + numRatings + \" ratings from \"\n      + numUsers + \" users on \" + numSongs + \" songs.\")\n    \n    val Array(training, test, validation) = ratings.randomSplit(Array(0.6, 0.2, 0.2))\n    \n    println(\"Training: \" + training.count() + \", validation: \" + validation.count() + \", test: \" + test.count())\n\n    val alpha = 0.01\n    val ranks = List(8, 12)\n    val lambdas = List(0.1, 10.0)\n    val numIters = List(10, 20)\n    \n    val numTraining = training.count()\n    val numValidation = validation.count()\n    val numTest = test.count()\n    var bestModel: Option[MatrixFactorizationModel] = None\n    var bestValidationRmse = Double.MaxValue\n    var bestRank = 0\n    var bestLambda = -1.0\n    var bestNumIter = -1\n    \n    def computeRmse(model: MatrixFactorizationModel, data: RDD[Rating], n: Long): Double = {\n    val predictions: RDD[Rating] = model.predict(data.map(x => (x.user, x.product)))\n    val predictionsAndRatings = predictions.map(x => ((x.user, x.product), x.rating))\n      .join(data.map(x => ((x.user, x.product), x.rating)))\n      .values\n    math.sqrt(predictionsAndRatings.map(x => (x._1 - x._2) * (x._1 - x._2)).reduce(_ + _) / n)\n    }\n    \n     for (rank <- ranks; lambda <- lambdas; numIter <- numIters) {\n      val model = ALS.trainImplicit(training, rank, numIter, lambda, alpha)\n      val validationRmse = computeRmse(model, validation, numValidation)\n      println(\"RMSE (validation) = \" + validationRmse + \" for the model trained with rank = \" \n        + rank + \", lambda = \" + lambda + \", and numIter = \" + numIter + \".\")\n      if (validationRmse < bestValidationRmse) {\n        bestModel = Some(model)\n        bestValidationRmse = validationRmse\n        bestRank = rank\n        bestLambda = lambda\n        bestNumIter = numIter\n      }\n    }\n    \n    val testRmse = computeRmse(bestModel.get, test, numTest)\n\n    println(\"The best model was trained with rank = \" + bestRank + \" and lambda = \" + bestLambda\n      + \", and numIter = \" + bestNumIter + \", and its RMSE on the test set is \" + testRmse + \".\")\n    \n    println(\"The test mean squared error is = \" + testRmse) \n    bestModel.get.save(sc,\"/Users/mathurtx/Documents/machine_learning/SongRecommendationEngine/data/bestCollaborativeFilteringModel\")","dateUpdated":"2016-12-16T08:31:26-0500","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1481595090535_1798951789","id":"20161212-211130_775241022","result":{"code":"SUCCESS","type":"TEXT","msg":"\nimport org.apache.spark.{SparkConf, SparkContext}\n\nimport org.apache.spark.mllib.recommendation.{ALS, Rating, MatrixFactorizationModel}\n\nimport org.apache.log4j.Logger\n\nimport org.apache.log4j.Level\n\nimport org.apache.spark.rdd._\n\nratings: org.apache.spark.rdd.RDD[org.apache.spark.mllib.recommendation.Rating] = MapPartitionsRDD[2778] at map at <console>:41\n\nnumRatings: Long = 4413912\n\nnumUsers: Long = 992\n\nnumSongs: Long = 1084873\nGot 4413912 ratings from 992 users on 1084873 songs.\n\n\n\ntraining: org.apache.spark.rdd.RDD[org.apache.spark.mllib.recommendation.Rating] = MapPartitionsRDD[2787] at randomSplit at <console>:47\ntest: org.apache.spark.rdd.RDD[org.apache.spark.mllib.recommendation.Rating] = MapPartitionsRDD[2788] at randomSplit at <console>:47\nvalidation: org.apache.spark.rdd.RDD[org.apache.spark.mllib.recommendation.Rating] = MapPartitionsRDD[2789] at randomSplit at <console>:47\nTraining: 2647301, validation: 884107, test: 882504\n\nalpha: Double = 0.01\n\nranks: List[Int] = List(8, 12)\n\nlambdas: List[Double] = List(0.1, 10.0)\n\nnumIters: List[Int] = List(10, 20)\n\nnumTraining: Long = 2647301\n\nnumValidation: Long = 884107\n\nnumTest: Long = 882504\n\nbestModel: Option[org.apache.spark.mllib.recommendation.MatrixFactorizationModel] = None\n\nbestValidationRmse: Double = 1.7976931348623157E308\n\nbestRank: Int = 0\n\nbestLambda: Double = -1.0\n\nbestNumIter: Int = -1\n\ncomputeRmse: (model: org.apache.spark.mllib.recommendation.MatrixFactorizationModel, data: org.apache.spark.rdd.RDD[org.apache.spark.mllib.recommendation.Rating], n: Long)Double\nRMSE (validation) = 10.853842823238885 for the model trained with rank = 8, lambda = 0.1, and numIter = 10.\nRMSE (validation) = 10.853656355394811 for the model trained with rank = 8, lambda = 0.1, and numIter = 20.\nRMSE (validation) = 10.878507361507294 for the model trained with rank = 8, lambda = 10.0, and numIter = 10.\nRMSE (validation) = 10.878507361507294 for the model trained with rank = 8, lambda = 10.0, and numIter = 20.\nRMSE (validation) = 10.85213525373266 for the model trained with rank = 12, lambda = 0.1, and numIter = 10.\nRMSE (validation) = 10.852226403231374 for the model trained with rank = 12, lambda = 0.1, and numIter = 20.\nRMSE (validation) = 10.878507361507294 for the model trained with rank = 12, lambda = 10.0, and numIter = 10.\nRMSE (validation) = 10.878507361507294 for the model trained with rank = 12, lambda = 10.0, and numIter = 20.\n\ntestRmse: Double = 10.764309205205556\nThe best model was trained with rank = 12 and lambda = 0.1, and numIter = 10, and its RMSE on the test set is 10.764309205205556.\nThe test mean squared error is = 10.764309205205556\n"},"dateCreated":"2016-12-12T09:11:30-0500","dateStarted":"2016-12-16T08:31:26-0500","dateFinished":"2016-12-16T08:36:08-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2595"},{"text":"","dateUpdated":"2016-12-16T08:23:50-0500","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1481894201308_-1438223968","id":"20161216-081641_1357535249","dateCreated":"2016-12-16T08:16:41-0500","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:2596"},{"text":"val songs = sc.textFile(\"/Users/mathurtx/Documents/machine_learning/data/lastfm-dataset-1K/trackIndexNamev5.csv\").map { line =>\n      val fields = line.split(\",\")\n      (fields(0).toInt, fields(1))\n    }.distinct().collect().toMap","dateUpdated":"2016-12-16T08:36:36-0500","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1481894148143_-1221518393","id":"20161216-081548_992524193","result":{"code":"SUCCESS","type":"TEXT","msg":"songs: scala.collection.immutable.Map[Int,String] = Map(769962 -> 12-Unison, 669325 -> June 7Th, 834212 -> Gladys And Lucy, 348877 -> Somebody To Love (Ian Knowles Remix), 895344 -> 69 Or 20, 177494 -> Arbeitstitel: Aller Achtung, 999043 -> Mommy'S Little Monster (Live), 868559 -> Fairytale Gone Bad (Instrumental Version), 921558 -> Cage Ii, 864012 -> Prozacunited, 592356 -> What'S The Reason I'M Not Pleasing You, 1042949 -> Cidesphere / Who Am I, 1024902 -> Return To Your Sad Existence Of Working For The Man, 282592 -> It'S Better With You, 402012 -> Das Model (Live), 922480 -> \"Vissi D'Arte, 504671 -> Vorrina Pi, 500897 -> Goldberg Variations; Bwv 988/Variation 23 A 2 Clav., 165114 -> Superfriends (Demo), 53767 -> At Home, 179367 -> Don'T Want You Woman, 140403 -> Party With The Anima..."},"dateCreated":"2016-12-16T08:15:48-0500","dateStarted":"2016-12-16T08:36:36-0500","dateFinished":"2016-12-16T08:36:46-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2597"},{"text":"import scala.io.Source\ndef loadRatings(path: String): Seq[Rating] = {\n    val lines = Source.fromFile(path).getLines()\n    val ratings = lines.map { line =>\n      val fields = line.split(\",\")\n      Rating(fields(0).toInt, fields(1).toInt, 1.0)\n    }.filter(_.rating > 0.0)\n    if (ratings.isEmpty) {\n      sys.error(\"No ratings provided.\")\n    } else {\n      ratings.toSeq\n    }\n  }","dateUpdated":"2016-12-16T08:38:34-0500","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1481766495505_455340791","id":"20161214-204815_163814853","result":{"code":"SUCCESS","type":"TEXT","msg":"\nimport scala.io.Source\n\nloadRatings: (path: String)Seq[org.apache.spark.mllib.recommendation.Rating]\n"},"dateCreated":"2016-12-14T08:48:15-0500","dateStarted":"2016-12-16T08:38:34-0500","dateFinished":"2016-12-16T08:38:35-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2598"},{"text":" val myRatings = loadRatings(\"/Users/mathurtx/Documents/machine_learning/data/lastfm-dataset-1K/myratings.csv\")","dateUpdated":"2016-12-16T08:38:39-0500","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1481656617964_-1419097346","id":"20161213-141657_1652593059","result":{"code":"SUCCESS","type":"TEXT","msg":"\nmyRatings: Seq[org.apache.spark.mllib.recommendation.Rating] = Stream(Rating(690,839,1.0), ?)\n"},"dateCreated":"2016-12-13T02:16:57-0500","dateStarted":"2016-12-16T08:38:39-0500","dateFinished":"2016-12-16T08:38:39-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2599"},{"text":"val myRatedSongsIds = myRatings.map(_.product).toSet","dateUpdated":"2016-12-16T08:38:43-0500","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1481766562489_820760301","id":"20161214-204922_1950486889","result":{"code":"SUCCESS","type":"TEXT","msg":"\nmyRatedSongsIds: scala.collection.immutable.Set[Int] = Set(839, 252562, 16868)\n"},"dateCreated":"2016-12-14T08:49:22-0500","dateStarted":"2016-12-16T08:38:43-0500","dateFinished":"2016-12-16T08:38:44-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2600"},{"text":"val candidates = sc.parallelize(songs.keys.filter(!myRatedSongsIds.contains(_)).toSeq)","dateUpdated":"2016-12-16T08:38:54-0500","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1481766675113_1069829112","id":"20161214-205115_1339752991","result":{"code":"SUCCESS","type":"TEXT","msg":"\ncandidates: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[5566] at parallelize at <console>:52\n"},"dateCreated":"2016-12-14T08:51:15-0500","dateStarted":"2016-12-16T08:38:54-0500","dateFinished":"2016-12-16T08:38:55-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2601"},{"text":"val recommendations = bestModel.get\n      .predict(candidates.map((690, _)))\n      .collect()\n      .sortBy(- _.rating)\n      .take(50)","dateUpdated":"2016-12-16T08:38:58-0500","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1481766709455_-1975812532","id":"20161214-205149_2120669413","result":{"code":"SUCCESS","type":"TEXT","msg":"recommendations: Array[org.apache.spark.mllib.recommendation.Rating] = Array(Rating(690,288,0.09927459489683213), Rating(690,176,0.09817818708273676), Rating(690,676,0.09517375989736598), Rating(690,5,0.09482765109034536), Rating(690,81,0.09463731128480014), Rating(690,295,0.09411582790911194), Rating(690,68,0.09235535852315183), Rating(690,165,0.09230496072438196), Rating(690,610,0.09214251332135787), Rating(690,252,0.09187472580535272), Rating(690,309,0.09115998895394606), Rating(690,726,0.09074597067220902), Rating(690,1072,0.09011227187976563), Rating(690,29,0.08994681733398313), Rating(690,187,0.08994316396451399), Rating(690,308,0.08878262830547036), Rating(690,16,0.08793642548206185), Rating(690,12,0.08760854354812218), Rating(690,235,0.0870318280169659), Rating(690,599,0.0868151..."},"dateCreated":"2016-12-14T08:51:49-0500","dateStarted":"2016-12-16T08:38:58-0500","dateFinished":"2016-12-16T08:39:07-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2602"},{"text":"var i = 1\n    println(\"Songs recommended for you:\")\n    recommendations.foreach { r =>\n      println(\"%2d\".format(i) + \": \" + songs(r.product))\n      i += 1\n    }\n","dateUpdated":"2016-12-16T08:39:14-0500","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1481765103352_-351857992","id":"20161214-202503_1017350982","result":{"code":"SUCCESS","type":"TEXT","msg":"\ni: Int = 1\nSongs recommended for you:\n 1: Neighborhood #3 (Power Out)\n 2: Rebellion (Lies)\n 3: Keep The Car Running\n 4: Untitled\n 5: Such Great Heights\n 6: Neighborhood #1 (Tunnels)\n 7: Karma Police\n 8: Heartbeats\n 9: Neighborhood #2 (Laika)\n10: Une Année Sans Lumière\n11: This Charming Man\n12: Clark Gable\n13: Grounds For Divorce\n14: Sleep\n15: Blue Light\n16: Because\n17: [Untitled]\n18: All I Need\n19: Maps\n20: Intervention\n21: There Is A Light That Never Goes Out\n22: Love Will Tear Us Apart\n23: Banquet\n24: Black Mirror\n25: No Cars Go\n26: New Slang\n27: The District Sleeps Alone Tonight\n28: Everything In Its Right Place\n29: Crown Of Love\n30: Brand New Colony\n31: Neighborhood #4 (7 Kettles)\n32: Staring At The Sun\n33: Subterranean Homesick Alien\n34: 7/4 (Shoreline)\n35: Where Is My Mind?\n36: Pda\n37: Sunday\n38: California\n39: Sometimes\n40: These Days\n41: Evil\n42: Bigmouth Strikes Again\n43: Hand In Glove\n44: Wake Up\n45: Lucky\n46: Come Together\n47: Caring Is Creepy\n48: Shine A Light\n49: Paranoid Android\n50: Bones\n"},"dateCreated":"2016-12-14T08:25:03-0500","dateStarted":"2016-12-16T08:39:14-0500","dateFinished":"2016-12-16T08:39:15-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2603"},{"text":"","dateUpdated":"2016-12-16T09:36:30-0500","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1481765038654_1359597061","id":"20161214-202358_1508025512","dateCreated":"2016-12-14T08:23:58-0500","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:2605"}],"name":"Collaborative Filtering","id":"2C5TQNYJG","angularObjects":{"2C42KCERA:shared_process":[],"2C2AGANKB:shared_process":[],"2C55ERKR5:shared_process":[],"2C2XR7KEM:shared_process":[],"2C2NQR27M:shared_process":[],"2C5Y6UP4Z:shared_process":[],"2C574SETK:shared_process":[],"2C48EWYVS:shared_process":[],"2C59Q91X1:shared_process":[],"2C3SHSCJR:shared_process":[],"2C58A3BXX:shared_process":[],"2C4RXX3H3:shared_process":[],"2C5SH75T9:shared_process":[],"2C5QFXQBV:shared_process":[],"2C49DZDUH:shared_process":[],"2C2D8KEQQ:shared_process":[],"2C49ZZF6U:shared_process":[],"2C2YERMC4:shared_process":[]},"config":{"looknfeel":"default"},"info":{}}